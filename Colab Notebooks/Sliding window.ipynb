{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Sliding window.ipynb","provenance":[],"authorship_tag":"ABX9TyMiaru6RL5idBaMk+ESVFyB"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"07ZoPULb-3vx","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"mwvzqQB-Z106"},"source":["### Global variables and methods"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"AmDsbNeXZ11J","colab":{}},"source":["# Cargamos datos\n","traj = pd.read_csv(files_path + traj_path, sep=\",\")\n","#gt = pd.read_csv(files_path + gt_path, sep=\",\")\n","pred_model = load_model(files_path+model_path+'metar_model.h5')\n","metar_1_clean = pd.read_csv(files_path+metar1_path, sep=\",\") # 30 minutos antes de aterrizaje\n","metar_2_clean = pd.read_csv(files_path+metar2_path, sep=\",\") # Momento de aterrizaje"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"TiJCop52Z11a","colab":{}},"source":["# Normalizamos los datos de trayectoria respecto de los máximos y mínimos (no siguen una distribución gaussiana)\n","def normalize_data(x_data, min_value, max_value):\n","  # Normalizamos datos de entrada entre un mínimo y máximo para obtener un valor entre 0 y 1\n","  # x_data tiene shape = (samples, timestemps)\n","  x_norm = np.zeros(x_data.shape)\n","  x_norm = (x_data-min_value)/(max_value-min_value)\n","\n","  return x_norm\n","\n","# Denormalizar los datos para crear la predicción en valores (coordenadas y altitud) reales\n","def denormalize_data(norm_data, min_value, max_value):\n","  # Desormalizamos datos normalizados entre 0 y 1 para obtener entre mínimo y máximo \n","  # x_data tiene shape = (samples, timestemps)\n","  x_data = np.zeros(norm_data.shape)\n","  x_data = (norm_data*(max_value-min_value))+min_value\n","\n","  return x_data\n","\n","# Estandarizamos los datos de metar respecto de la media y std de los datos de entrenamiento\n","def standarize_data(x_data):\n","  # Se utiliza la media y std de los datos de entrenamiento para estandarizar lso datos de test\n","\n","  x_standarized = np.zeros(x_data.shape)\n","\n","  for i in range(len(x_data.T)):\n","    std = np.std(x_data.T[i])\n","    if std ==0: std=1 # Si la std es 0, cambiamos por 1 para evitar dividir entre 0\n","    x_standarized.T[i] = (x_data.T[i]-np.mean(x_data.T[i]))/std\n","    \n","  return x_standarized\n","\n","## TODO: modificar este método para que sea funcional en este caso y poder crear las particiones de test y train\n","\n","# Mezclar datos de train y test y crear particiones\n","def shuffle_and_partition(x_traj, id_list, y, trainP):\n","  # x=inputs, y=outputs, trainP=porcentaje de train\n","  s = np.arange(x_traj.shape[0])\n","  np.random.shuffle(s)\n","  x_traj, id_list, y = x_traj[s], np.array(id_list)[s], y[s]\n","\n","  # Asignamos particiones de train y test\n","  n_part = round(trainP*len(x_traj))\n","\n","  x_traj_train, x_traj_test, id_list_train, id_list_test, y_train, y_test = x_traj[:n_part], x_traj[n_part:], id_list[:n_part], id_list[n_part:], y[:n_part], y[n_part:]\n","  return x_traj_train, x_traj_test, id_list_train, id_list_test, y_train, y_test"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gLQS-ad-DORg","colab_type":"text"},"source":["### Tratamiento datos de trayectoria"]},{"cell_type":"markdown","metadata":{"id":"FB40cImXPLvK","colab_type":"text"},"source":["Pasamos las variables a formato float y nos quedamos los datos"]},{"cell_type":"code","metadata":{"id":"mpzj3DazGVJS","colab_type":"code","outputId":"84679b71-0a2c-4b7f-86e7-38301417b55b","executionInfo":{"status":"ok","timestamp":1581951387693,"user_tz":-60,"elapsed":979,"user":{"displayName":"Jesus Angel Cantero Ramis","photoUrl":"","userId":"14828881599686698776"}},"colab":{"base_uri":"https://localhost:8080/","height":109}},"source":["import re\n","variables = ['hour', 'minute', 'second', 'altitude', 'direction', 'latitude', 'longitude', 'speed']\n","for v in variables:\n","  n = 0\n","  for i in traj[v]:  \n","    result = re.search('\\[(.*)\\]', i)\n","    traj[v][n] = [float(j) for j in result.group(1).split(',')]\n","    n +=1\n","fl_id_list = list(traj['fl_id'])\n","threshold = list(traj['threshold'])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  import sys\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"08dLivg6KBft","colab_type":"code","colab":{}},"source":["# Separar una serie de datos secuenciales de una sola variable en muestras diferentes y la salida - Preparación para LSTM univariate\n","def split_sequence(sequence, n_steps):\n","\tX, y = list(), list()\n","\tfor i in range(len(sequence)):\n","\t\tend_ix = i + n_steps # Fin de secuencia\n","\t\tif end_ix > len(sequence)-1: # Comprobar si hemos rebasado el final\n","\t\t\tbreak\n","\t\tseq_x, seq_y = sequence[i:end_ix], sequence[end_ix] # Separar entre entrada y salida\n","\t\tX.append(seq_x)\n","\t\ty.append(seq_y)\n","\treturn np.array(X), np.array(y)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"X2rUaf9odOJE","colab_type":"code","colab":{}},"source":["import numpy as np\n","# Separar una serie de datos secuenciales de una varas variables en muestras diferentes y la salida - Preparación para LSTM multivariate\n","def split_sequences(sequences, n_steps):\n","\tX, y = list(), list()\n","\tfor i in range(len(sequences)):\n","\t\t# find the end of this pattern\n","\t\tend_ix = i + n_steps\n","\t\t# check if we are beyond the dataset\n","\t\tif end_ix > len(sequences)-1:\n","\t\t\tbreak\n","\t\t# gather input and output parts of the pattern\n","\t\tseq_x, seq_y = sequences[i:end_ix, :], sequences[end_ix, :]\n","\t\tX.append(seq_x)\n","\t\ty.append(seq_y)\n","\treturn np.array(X), np.array(y)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gwLEwTlJ-POm","colab_type":"text"},"source":["Definición del modelo"]},{"cell_type":"code","metadata":{"id":"2TuilTrOejal","colab_type":"code","outputId":"536218f4-5824-4543-e6b3-43a9ce4924aa","executionInfo":{"status":"ok","timestamp":1582191138880,"user_tz":-60,"elapsed":320828,"user":{"displayName":"Jesus Angel Cantero Ramis","photoUrl":"","userId":"14828881599686698776"}},"colab":{"base_uri":"https://localhost:8080/","height":954}},"source":["# define model\n","model = Sequential()\n","#model.add(LSTM(32,dropout = 0.1,recurrent_dropout=0.5,activation='relu',return_sequences=True, input_shape=(n_steps, n_features)))\n","#model.add(layers.Embedding(n_features, 512))\n","model.add(LSTM(30,dropout = 0.2,recurrent_dropout = 0.2 ,return_sequences = True))\n","model.add(LSTM(60,dropout = 0.2,recurrent_dropout = 0.2))\n","#model.add(Dense(64,activation = 'relu'))\n","#model.add(Dropout(0.2))\n","model.add(Dense(n_features))\n","RMS = optimizers.RMSprop()\n","#Adam = optimizers.Adam()\n","model.compile(optimizer=RMS, loss='mse')\n","#model.compile(optimizer='Adam', loss='mae')\n","# fit model\n","model.fit(X, Y, epochs=epochs, batch_size=batch_size, verbose=1,validation_split = validation_split)\n","\n","#Save model\n","model.save(files_path+model_path+'uv_traj_model.h5')\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train on 33310 samples, validate on 8328 samples\n","Epoch 1/25\n","33310/33310 [==============================] - 26s 768us/step - loss: 0.0138 - val_loss: 0.0036\n","Epoch 2/25\n","33310/33310 [==============================] - 12s 354us/step - loss: 0.0066 - val_loss: 0.0030\n","Epoch 3/25\n","33310/33310 [==============================] - 12s 356us/step - loss: 0.0058 - val_loss: 0.0028\n","Epoch 4/25\n","33310/33310 [==============================] - 12s 356us/step - loss: 0.0054 - val_loss: 0.0032\n","Epoch 5/25\n","33310/33310 [==============================] - 12s 350us/step - loss: 0.0051 - val_loss: 0.0023\n","Epoch 6/25\n","33310/33310 [==============================] - 12s 350us/step - loss: 0.0052 - val_loss: 0.0030\n","Epoch 7/25\n","33310/33310 [==============================] - 12s 356us/step - loss: 0.0051 - val_loss: 0.0023\n","Epoch 8/25\n","33310/33310 [==============================] - 12s 352us/step - loss: 0.0050 - val_loss: 0.0026\n","Epoch 9/25\n","33310/33310 [==============================] - 12s 351us/step - loss: 0.0050 - val_loss: 0.0027\n","Epoch 10/25\n","33310/33310 [==============================] - 12s 348us/step - loss: 0.0051 - val_loss: 0.0026\n","Epoch 11/25\n","33310/33310 [==============================] - 12s 348us/step - loss: 0.0049 - val_loss: 0.0024\n","Epoch 12/25\n","33310/33310 [==============================] - 12s 363us/step - loss: 0.0048 - val_loss: 0.0021\n","Epoch 13/25\n","33310/33310 [==============================] - 12s 353us/step - loss: 0.0047 - val_loss: 0.0022\n","Epoch 14/25\n","33310/33310 [==============================] - 12s 351us/step - loss: 0.0047 - val_loss: 0.0022\n","Epoch 15/25\n","33310/33310 [==============================] - 11s 344us/step - loss: 0.0038 - val_loss: 0.0030\n","Epoch 16/25\n","33310/33310 [==============================] - 12s 351us/step - loss: 0.0031 - val_loss: 0.0038\n","Epoch 17/25\n","33310/33310 [==============================] - 12s 353us/step - loss: 0.0025 - val_loss: 0.0067\n","Epoch 18/25\n","33310/33310 [==============================] - 12s 346us/step - loss: 0.0021 - val_loss: 0.0121\n","Epoch 19/25\n","33310/33310 [==============================] - 12s 351us/step - loss: 0.0019 - val_loss: 0.0134\n","Epoch 20/25\n","33310/33310 [==============================] - 12s 349us/step - loss: 0.0018 - val_loss: 0.0105\n","Epoch 21/25\n","33310/33310 [==============================] - 12s 347us/step - loss: 0.0017 - val_loss: 0.0158\n","Epoch 22/25\n","33310/33310 [==============================] - 12s 349us/step - loss: 0.0016 - val_loss: 0.0152\n","Epoch 23/25\n","33310/33310 [==============================] - 11s 345us/step - loss: 0.0017 - val_loss: 0.0113\n","Epoch 24/25\n","33310/33310 [==============================] - 12s 347us/step - loss: 0.0016 - val_loss: 0.0137\n","Epoch 25/25\n","33310/33310 [==============================] - 12s 350us/step - loss: 0.0015 - val_loss: 0.0142\n"],"name":"stdout"}]}]}