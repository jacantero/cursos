{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"P2. Introducción a TF: Optimización y regresión lineal_JUN19.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"0D4v2vymw-ZX","colab_type":"text"},"source":["**PRÁCTICA 2. INTRODUCCIÓN A TENSORFLOW: OPTIMIZACIÓN Y REGRESIÓN LINEAL**"]},{"cell_type":"markdown","metadata":{"id":"XiFN7VY4z0Do","colab_type":"text"},"source":["**Conceptos necesarios de teoría**:\n","Tensores en TF, Variables vs Placeholders, SGD, Boston dataset"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Bl42uGwRb_SZ"},"source":["En la práctica anterior, programamos el **Fordward Pass** y el algoritmo básico del aprendizaje profundo, el **Backpropagation**, empleando la librería científica **Numpy**. El código que desarrollamos no estaba optimizado ni ampliamente validado. Debido a estos dos aspectos, cuando se desean entrenar redes neuronales se hace uso de librerias de más alto nivel. En esta segunda sesión práctica vamos a trabajar con la librería **TensorFlow**. ¿Como importamos dicha librería en nuestro Notebook de Colab?"]},{"cell_type":"code","metadata":{"id":"wh9LoykybaSs","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","print(tf.__version__)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mv7s8x1gcBuo","colab_type":"text"},"source":["TensorFlow es un framework desarrollado y mantenido por **Google** que permite la ejecución de operaciones matemáticas, mediante diagramas de flujo de datos, de una forma optimizada en una CPU o GPU. Vamos a **listar los dispositivos locales** para comprobar que tenemos disponible la GPU que Google Colab nos ofrece:"]},{"cell_type":"code","metadata":{"id":"kMkvxESycCYA","colab_type":"code","colab":{}},"source":["from tensorflow.python.client import device_lib\n","\n","def get_available_devices():\n","  local_device_protos = device_lib.list_local_devices()\n","  return [x.name for x in local_device_protos]\n","\n","print(get_available_devices())"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VYCsBGTcfXXd","colab_type":"text"},"source":["Vaya... ¿Por qué aparecen 2 CPUs y 2 GPUs?**¿Que significa XLA?** Efectua una búsqueda rápida en Google para salir de dudas."]},{"cell_type":"markdown","metadata":{"id":"NAdam6uPbapY","colab_type":"text"},"source":["Tal y como hemos visto en el apartado teórico, TensorFlow tiene unas características un tanto peculiares:\n","\n","1.   TensorFlow utiliza **tensores** para realizar las operaciones.\n","\n","2.   En TensorFlow, **primero se definen las operaciones a realizar** (construimos el **grafo**), y **luego se ejecutan** (se ejecuta el grafo).\n","\n","3.   Permite ejecutar el código implementado paralelamente o en **una o varias GPUs**, a elección del usuario.\n","\n","Sin más dilación vamos a ver como se define un tensor y como se pueden realizar operaciones básicas entre ellos. Ves ejecutando cada una de las celdas y asegúrate que comprendes la salida de todos los comandos *print*."]},{"cell_type":"code","metadata":{"id":"ynyaV6fJizJJ","colab_type":"code","colab":{}},"source":["import numpy as np\n","import tensorflow as tf\n","\n","# Creo un numpy array\n","arr1d = np.array([1, 5.5, 3, 15, 20])\n","\n","# Del cual puedo ver tanto su contenido como ciertas propiedades\n","print(arr1d)\n","print (arr1d.ndim)\n","print (arr1d.shape)\n","print (arr1d.dtype)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9sEvamEOjA3p","colab_type":"code","colab":{}},"source":["# Cuando convierto a tensor y trato de ver el contenido ya no es posible\n","tensor1d = tf.convert_to_tensor(arr1d,tf.float64)\n","print(tensor1d)\n","\n","# Para ver el contenido de un tensor tengo que ejecutar una sesión\n","sess = tf.Session() # ¡¡¡ Busca en la documentación de TensorFlow información acerca de una sesión !!!\n","print(sess.run(tensor1d))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_WW7GKE6jQ8q","colab_type":"code","colab":{}},"source":["# Vamos a sumar dos tensores\n","tensor1d_bis = tf.convert_to_tensor([9, 4.5, 7, 5, 0], tf.float64)\n","my_sum = tf.add(tensor1d, tensor1d_bis)\n","sess = tf.Session()\n","print(sess.run(my_sum))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9izA32SGjVSy","colab_type":"code","colab":{}},"source":["# Multipliquemoslos (elemento a elemento)\n","my_mul = tf.multiply(tensor1d, tensor1d_bis) # Producto elemento a elemento\n","sess = tf.Session()\n","print(sess.run(my_mul))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"v4hsV_VfjgHS","colab_type":"code","colab":{}},"source":["# Ahora un producto escalar de tensores 1D\n","product1 = tf.tensordot(tensor1d, tensor1d_bis, 1) # OJO! No hace falta transponer\n","sess = tf.Session()\n","print(sess.run(product1))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"E4c_NMZ2pQTB","colab_type":"code","colab":{}},"source":["# Vamos con un producto escalar de tensores 2D\n","matrix1 = tf.constant([[3., 3.]])\n","matrix2 = tf.constant([[2.], [2.]])\n","product2 = tf.matmul(matrix1, matrix2) # Producto matricial\n","sess = tf.Session()\n","print(sess.run(matrix1))\n","print(sess.run(matrix2))\n","print(sess.run(product2))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ceSlmno7jxmU","colab_type":"code","colab":{}},"source":["sess2 = tf.Session()\n","matrix1 = tf.constant([[1., 1.]])\n","matrix2 = tf.constant([[2.], [2.]])\n","product2 = tf.matmul(matrix1, matrix2) # Producto matricial\n","print(sess2.run(product2))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mEIt2BPJjxIU","colab_type":"text"},"source":["¿Que tal estas primeras operaciones empleando TensorFlow? Si os habeís fijado detenidamente hay un par de instrucciones que hemos ido repitiendo a lo largo de las operaciones. **``sess = tf.Session()``** es la instrucción básica de TF, con ella abrimos una nueva sesión durante la cuál podremos realizar las operaciones deseadas. Dichas operaciones se definen en forma de grafo, bien antes de abrir la sesión o una vez abierta (mediante sentencias como **``grafo = tf.add(x1, x2)``**; **``grafo = tf.multiply(x1, x2)``**; **``grafo = tf.tensordot(x1, x2, axis)``**, etc.). Una vez creado el grafo, con la expresión **``tf.run(grafo)``** ejecutamos todas las operaciones contenidas en el mismo (i.e. se ejecuta la última operación y las operaciones contenidas en las variables de entrada de dicha última operación).\n","\n","Es importante destacar que también es posible abrir una nueva sesión empleando el comando **``with``** y sobre todo que la sesión debe cerrarse para liberar los recursos mediante el comando **``sess.close()``**.\n"]},{"cell_type":"code","metadata":{"id":"JyrZvbrvW3mJ","colab_type":"code","colab":{}},"source":["with tf.Session() as sess:\n","  my_res = sess.run([product2])\n","  print(my_res)\n","sess.close()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Gh2i5weyaNIF","colab_type":"text"},"source":["Como se ha comentado anteriormente, el código implementado se puede ejecutar en CPU, en GPU o en multiples GPUs. Mediante TF podemos listar los diferentes dispositivos (como ya hemos visto) y **ejecutar una sesión utilizando el/los dispositivo/s que creamos conveniente/s**:"]},{"cell_type":"code","metadata":{"id":"kaTwBn40adFY","colab_type":"code","colab":{}},"source":["with tf.Session() as sess:\n","  with tf.device(\"/device:XLA_GPU:0\"):\n","    matrix1 = tf.constant([[3., 3.]])\n","    matrix2 = tf.constant([[2.],[2.]])\n","    last_prod = tf.matmul(matrix1, matrix2)\n","    print(sess.run(last_prod))\n","sess.close()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RbTLPLPKqsB1","colab_type":"text"},"source":["El último aspecto que nos queda por introducir son las **sesiones interactivas** que brinda TF. Mediante una sesión interactiva es posible establecer una sesión activa por defecto mientras esta se encuentra bajo construcción. Empleando el método **``tf.TENSOR.eval()``** se puede visualizar el contenido de un tensor sin necesidad de tener que ejecutar el grafo tal y como haciamos en una sesión estática (recuerda mediante **``tf.run(grafo)``**). De la misma forma es posible llevar a cabo las operaciones que se deseen mediante el comando **``tf.OPERACION.run()``**. Vamos a ejemplificar el concepto de sesión interactiva creando una distribución Gaussiana y graficándola.\n","\n","$f(x) = \\dfrac{1}{\\sigma\\sqrt{2\\pi}}e^{-\\dfrac{1}{2}\\left(\\dfrac{x-\\mu}{\\sigma}\\right)^2}$"]},{"cell_type":"code","metadata":{"id":"mbUhDd2aspVr","colab_type":"code","colab":{}},"source":["# Importo librerias necesarias para visualización\n","import matplotlib.pyplot as plt\n","\n","# Inicio sesión interactiva\n","sess = tf.InteractiveSession()\n","\n","# Parámetros\n","n_values = 64\n","sigma = 1.0\n","mean = 0\n","\n","# Creo Gaussiana de 64 vaores y muestro\n","x = tf.linspace(-5.0, 5.0, n_values)\n","x.eval()\n","gaussian_function = (tf.exp(tf.negative(tf.pow(x-mean, 2) / (2.0 * tf.pow(sigma, 2.0)))) * (1.0 / (sigma * tf.sqrt(2.0 * np.pi))))\n","plt.plot(gaussian_function.eval())\n","\n","# Cierro sesión interactiva\n","sess.close()\n","tf.InteractiveSession.close(sess)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4eanx4o1XoB1","colab_type":"text"},"source":["Por el momento todo el contenido que hemos ido creando lo hemos asigando directamente a diferentes variables. Concretamente en el ejemplo anterior hemos almacenado $n$ puntos equiespaciados en el rango [-5,5] en la variable **``x``**, mientras que los valores de la distibución Gaussiana los hemos almacenado en una variable denominada **``gaussian_function``**. Dichas **variables** son **definidas e inicializadas con un tensor de determinas dimensiones** y el **contenido de las mismas puede ir actualizandose en tiempo de ejecución**, por ejemplo, en el proceso de actualización de los pesos de una red neuronal. \n","\n","En TF a parte de variables existen **``placeholders``**. Los placeholders no son más que **resrvas de espacios de memoria**. Dichas resrvas de memoria se pueden realizar **definiendo las dimensiones** del tensor que contendrá el placeholder **o sin definirlas**, puesto que se trata de reserva de memoria dinámica. El contenido de un placeholder **se rellena en tiempo de ejecución** (i.e. cuando ejecutamos **``tf.Session.run()``**) y se utiliza mayoritariamente para alimentar al grafo con datos de entrada, por ejemplo, en un placeholder almacenariamos el dataset para entrenar una red neuronal. A diferencia de las variables, **los placeholders no pueden modificar su contenido en tiempo de ejecución**. Vamos a ver un ejemplo para entenderlo mejor:"]},{"cell_type":"code","metadata":{"id":"5S3i_AqUtfQ4","colab_type":"code","colab":{}},"source":["# Instanciemos un placeholder definiendo dimensiones\n","x = tf.placeholder(tf.int32, shape=[4])\n","print (x.get_shape())\n","# El valor que proporciona x.get_shape() son las dimensiones estáticas de x (en este caso un vector de 4 elementos)\n","\n","# Apliquemos la función unique ¡¡¡ Busca en la documentación de TF para que sirve dicha función !!!\n","y, _ = tf.unique(x)\n","print (y.get_shape())\n","\n","#¿Que está ocurriendo?¿Por que sucede esto? \n","#???"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z9M8_zcHwyka","colab_type":"code","colab":{}},"source":["# Vamos a ejecutar el grafo en una sesión\n","sess = tf.Session()\n","print (sess.run(y, feed_dict={x: [0, 1, 1, 3]}).shape) # Ejemplo 1\n","print (sess.run(y, feed_dict={x: [0, 0, 0, 0]}).shape) # Ejemplo 2\n","sess.close()\n","\n","# ¿Que sucede ahora?¿Por qué las dimensiones son conocidas? Justifica las dimensiones que salen\n","#???"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zlgzGkeKRaC-","colab_type":"text"},"source":["Una vez introducido lo que es un tensor y la forma de operar con ellos, vamos a dirigir ya el uso de TF al ámbito de las redes neuronales. Tal y como hemos visto en lo que llevamos de teoría como en la sesión práctica anterior, el **corazón de una red neuronal** es el algoritmo de **backpropagation** que tiene como objetivo optimizar los pesos **minimizando** la **función de pérdidas** o **función de coste**. ¿Y como podemos minimizar una determinada función empleando TF?  Pues vamos a verlo con un ejemplo, vamos a minimizar la función $f(x)=log(x)^2$: "]},{"cell_type":"code","metadata":{"id":"29doEisbQURa","colab_type":"code","colab":{}},"source":["# Hallemos el mínimo de la función y = log(x)^2\n","x = tf.Variable(2, dtype=tf.float32) # Le damos un primer valor a nuestra x\n","y = tf.square(tf.log(x)) # Definimos la función\n","opt = tf.train.GradientDescentOptimizer(0.5) # Instanciamos el optimizador pasandole como parámetro el learning rate\n","train = opt.minimize(y) # Minimizamos función\n","\n","init = tf.initializers.global_variables() # Inicializamos las variables ¡¡¡ Busca en la documentación de TF información acerca de este método !!!\n","\n","with tf.Session() as session: # Ejecutamos los grafos\n","    session.run(init) #Inicializamos variables\n","    print('[INFO]: Starting at', 'x = ', session.run(x), '- log(x)^2:', session.run(y))\n","    for step in range(10):\n","      session.run(train)\n","      print('[INFO]: Step ', step, '---> x: ', session.run(x), '- log(x)^2: ', session.run(y))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kzGZs1QKWpdL","colab_type":"code","colab":{}},"source":["# Representa (empleando matplotlib) la función y = log(x)^2 y obten el mínimo y la posición del mismo empleando numpy\n","# Para ello, crea un vector de 100 puntos equiespaciados en el rango [0,10] (ver np.linspace)\n","#??? #Valores de x \n","#??? #Valores de y \n","#??? #Obtener mínimo y posición y mostrar valores por pantalla\n","#??? #Mostrar función \n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WgY3hhgjov4a","colab_type":"text"},"source":["A continuación responda a las siguientes cuestiones acerca del ejemplo anterior:\n","\n","- ¿Tienden a la misma solución ambas aproximaciones?¿Que significa esto? \n","- ¿Que efecto tendría sobre el valor del mínimo disminuir el valor de lr? \n","- Disminuye la tasa de aprendizaje a lr = 0.05, ¿Que observas?¿Que parámetro del código necesitas modificar para observar resultados coherentes? "]},{"cell_type":"markdown","metadata":{"id":"ONYrdBX0_A8M","colab_type":"text"},"source":["\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"6CCFoOHXwRcX","colab_type":"text"},"source":["Para poner en práctica todo lo aprendido, vamos a resolver uno de aquellos problemas de optimización típicos de bachillerato mediante TensorFlow.\n","\n","**EJERCICIO 1.**  Xiaomi va a lanzar al mercado un nuevo smartphone y quiere diseñar el packaging del mismo. La idea es desarrollar un envase en forma de prisma de base cuadrada. El volumen del envase debe ser de 80 $cm^3$. El material para fabricar las caras laterales y la tapa del envase cuesta 1 céntimo de euro por $cm^2$. El material para fabricar la base debe ser más resistente y cuesta 1.5 céntimos de euro por $cm^2$.\n","\n","1.   Calcula las dimensiones del envase para que su coste sea el menor posible.\n","2.   Calcula cuál es el coste mínimo, expresado en euros, que tendrá el envase."]},{"cell_type":"markdown","metadata":{"id":"sshrnGCay12w","colab_type":"text"},"source":["Si recordaís con los datos del encunciado debemos plantear un sistema de ecuaciones. Una de las ecuaciones nos proporcionará una relación y la otra será la función objetivo a minimizar. VAMOS ALLÁ:\n","\n","- El volumen de un prisma es $Vp = x * y * h$, como sabemos que la base es cuadrada: $Vp = x*x*h = 80$.\n","- Por otra parte tenemos que plantear otra ecuación que involucre la superficie del envase y la relacione con el coste: $C(x) = 1c€/cm^2 * (4x*h + x^2) + 1.5 c€/cm^2 * x^2$ = $4xh+x^2 + 1.5x^2$ = $4xh+2.5x^2$.\n","\n","Bien, ahora que ya tenemos las dos ecuaciones, de la primera de ellas (la relación) despejamos $x$ y la sustituimos en la función de coste (función objetivo o función a minimizar), resultando:\n","\n","$C(x) = \\dfrac{320}{x} + 2.5x^2$\n","\n","Esta es la función objetivo que debeís minimizar haciendo uso de la librería TensorFlow, tal y como hemos hecho antes con la función $y = log(x)^2$, para poder responder a las dos cuestiones planteadas en el enunciado."]},{"cell_type":"code","metadata":{"id":"iMiT7B533qTt","colab_type":"code","colab":{}},"source":["# Hallemos el mínimo de la función C(x) = 320/x + 2.5x^2\n","\n","# Inicialización de la variable x (Utiliza la función random_uniform de TF)\n","#???\n","\n","# Función de coste a minimizar\n","#???\n","\n","#Instanciar el optimizardor pasándole como parámetro el learning rate\n","#???\n","\n","# Minimizar la función objetivo\n","#???\n","\n","# Inicializar las variables del grafo\n","#???\n","\n","# Ejecución del grafo\n","with tf.Session() as session:\n","    #??? #Inicializamos variables\n","    old_solution = 0\n","    tolerance = 1e-4\n","    for step in range(500): # Dejar vacío el parámetro de número de pasos\n","      #??? # Entrenamos\n","      #??? # Nueva solución\n","      # Comprobamos si se ha alcanzado la solución óptima\n","      if np.abs(solution - old_solution) < tolerance:\n","        print(\"\\n El envase óptimo tendrá dimensiones x = {} cm, h = {} cm dando lugar a un coste de C = {} €\".format(solution, 80/(solution*solution), session.run(c)/100))\n","        break\n","      # Si no es así actualizo la solución vieja y muestro por pantalla 1 de cada 10 iteraciones\n","      old_solution = solution\n","      if step % 10 == 0:\n","        print('[INFO]: Step ', step, \"---> x = \" + str(old_solution), \"- C = \" + str(session.run(c)))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sodMxtm7rzG-","colab_type":"text"},"source":["A continuación responda a las siguientes cuestiones acerca del ejemplo anterior:\n","\n","- ¿Qué valor de tasa de aprendizaje y número de pasos has utilizado para el entrenamiento? Si has empleado los valores del ejercicio anterior observarás un comportamiento un tanto extraño en el proceso de aprendizaje. ¿Que significa esto? \n","\n","- Prueba a fijar una tasa de aprendizaje 100 veces más pequeña para dar pasos mucho más cortos en la búsqueda de la solución óptima, por consiguiente establece un número de pasos mucho mayor, por ejemplo 500. ¿Que ocurre ahora? Justifica la respuesta. "]},{"cell_type":"markdown","metadata":{"id":"wSI1WWintdJX","colab_type":"text"},"source":["\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"cz5SVAfcUqRU","colab_type":"text"},"source":["Para finalizar esta segunda práctica, vamos a realizar una **regresión lineal** sobre un determinado conjunto de datos $X$. Dicha regresión lineal vendrá dada por la ecuación de la recta de la forma $\\hat{Y} = XW + b$. La solución óptima del ajuste de la recta ($W_{opt}, b_{opt}$) sobre la distribución de datos se puede obtener minimizando la función error cuadrático medio definida como  $MSE = \\frac{1}{N}\\sum_{i=1}^{N}(\\hat{y}_i - y_i)^2$ donde $N$ es el número de muestras del conjunto de datos e $Y$ es un vector con el *ground truth* de los mismos.\n","\n","**EJERCICIO 2.** El **Boston dataset** es un conjunto de datos para el análisis de los precios de las viviendas en la región de Boston. Dicho conjunto de datos esta formado por **506 muestras**. Cada una de ellas viene definida por **trece características** de la vivienda en cuestión y su precio de mercado (i.e. target). Es interesante conocer las características de el conjunto de datos, por lo que la primera tarea de este ejercicio es leer detenidamente la descripción del dataset y sus características [aqui](https://www.kaggle.com/c/boston-housing). A continuación, siguiendo las indicaciones anteriores se debe implementar un algoritmo que dado el nombre de una característica y el target, sea capaz de ajustar una recta que permita realizar predicciones futuras."]},{"cell_type":"code","metadata":{"id":"h5miVzFpc7YS","colab_type":"code","colab":{}},"source":["# Importamos y cargamos el dataset\n","from sklearn import datasets\n","boston = datasets.load_boston()\n","\n","# Selección de característica y del target (en este caso precio de la vivienda medio expresado en $1000s)\n","name_feature = 'DIS' #Probar con RM, NOX y DIS  \n","f = np.where(boston.feature_names == name_feature)\n","xs = boston.data[:,f[0][0]]\n","ys = boston.target\n","# Número de muestras\n","n_observations = boston.target.shape[0]\n","\n","# Crear dos placeholders (en float32) que contendrán tanto los datos (X) como la etiqueta de los mismos (Y)\n","#???\n","#???\n","\n","# Inicializar W y b con valores aleatorios siguiendo una distribución normal (hacer uso de función random_normal de TF)\n","#???\n","#???\n","\n","# Obtener predicciones (i.e. \\hat{Y})\n","#???\n","\n","# Función de pérdidas (i.e. MSE)\n","#???\n","\n","# Instanciar optimizador y minimizar MSE\n","#???\n","\n","# Inicializar las variables del grafo\n","#???\n","\n","# Número de iteraciones de entrenamiento\n","n_epochs = 2500\n","\n","# Ejecución del grafo\n","with tf.Session() as session:\n","  #??? #Inicializamos variables\n","  prev_training_loss = 0.0\n","  for epoch_i in range(n_epochs):\n","    for (x, y) in zip(xs, ys):\n","      # Lanzar el entrenamiento pasando cada vez un punto de nuestro set de datos (documentación Session.run, parámetro feed_dict)\n","      #???\n","    # Cálcular MSE tras de la época en cuestión empleando todos los datos (documentación Session.run, parámetro feed_dict)     \n","    #???\n","      \n","    if epoch_i % 20 == 0:\n","      print(\"[INFO]: Época {} ---> MSE = {}\".format(epoch_i, training_loss))\n","        \n","    if(np.abs(prev_training_loss - training_loss) < 0.000001):\n","      break;\n","    prev_training_loss = training_loss\n","    \n","  # Dibujamos el resultado.\n","  plt.scatter(xs, ys)\n","  plt.plot(xs, Y_pred.eval(feed_dict={X: xs}, session=session))"],"execution_count":0,"outputs":[]}]}