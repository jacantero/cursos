{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"P4. CNNs con Keras para la clasificación de imágenes.ipynb","version":"0.3.2","provenance":[{"file_id":"1ttBWycTPm4rMLUI0ri0qd-AmIRYeZgo1","timestamp":1549968277278}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"xJ-9NaDo39w6","colab_type":"text"},"source":["**PRÁCTICA 4. CCNs CON KERAS PARA LA CLASIFICACIÓN DE IMÁGENES**"]},{"cell_type":"markdown","metadata":{"id":"zPjamI7EYoTC","colab_type":"text"},"source":["Despues de trabajar durante las dos prácticas anteriores con la librería de bajo nivel denominada TensorFlow, en la presente práctica se va a introducir un framework de alto nivel para el entrenamiento de redes neuronales denominado **Keras**. Esta librería fue desarrollada por **François Chollet** en 2015 con el objetivo de **simplificar la programación de algoritmos basados en aprendizaje profundo** ofreciendo un conjunto de abstracciones más intuitivas y de alto nivel. Keras hace uso de librerías de más bajo nivel o ***backend*** por detrás, concretamente se puede escoger entre **TensorFlow,  Microsoft Cognitive Toolkit o Theano**. Durante las sesiones prácticas que restan en el curso haremos uso de la librería Keras con TensorFlow como backend."]},{"cell_type":"markdown","metadata":{"id":"ev8wEZFrbr5q","colab_type":"text"},"source":["**EJERCICIO 1.** En primer lugar y con el objetivo de familiarizarnos con esta nueva librería, el primer ejercicio consistirá en replicar la última versión de la red neuronal profunda de la práctica anterior **empleando Keras**.  Si recordaís  el objetivo que perseguía la práctica anterior era el de **clasificar el dataset de dígitos manuscritos denominado MNIST**, así que vamos a ello:\n","\n","- **Analiza el siguiente código con atención** y **busca en la [documentación de Keras](https://keras.io/)** cada una de las funciones que se utilizan. No pases al siguiente apartado hasta no tener **totalmente claro** cada uno de los **comandos** que se emplean y los **parámetros de entrada** de dichas funciones.\n","\n","- **Ejecuta el proceso de entrenamiento de la red**. Posteriormente **añade capas de dropout (manteniendo el 50% de las neuronas de cada capa) después de cada una de las *hidden layers*** y vuelve a lanzar la red. En el código aparece comentada las instrucciones para añadir las capas de dropout. \n","\n","- Realiza de nuevo estas dos pruebas cambiando el optimizador **SGD por Adam**. ¿Qué configuración es la que mejores resultados proporciona sin mostrar signos de overfitting? "]},{"cell_type":"code","metadata":{"id":"zzPvYDu2W5kn","colab_type":"code","colab":{}},"source":["# Imports necesarios\n","import numpy as np\n","from sklearn.metrics import classification_report\n","from keras.models import Sequential\n","from keras.layers.core import Dense\n","from keras.layers import Dropout\n","from keras.optimizers import SGD\n","from keras.optimizers import Adam\n","import matplotlib.pyplot as plt\n","\n","# Importamos el dataset MNIST y cargamos los datos\n","from tensorflow.examples.tutorials.mnist import input_data\n","mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n","\n","# Implementamos la red empleando Keras\n","model = Sequential()\n","model.add(Dense(200, input_shape=(784,), activation=\"relu\"))\n","#model.add(Dropout(0.5))\n","model.add(Dense(100, activation=\"relu\"))\n","#model.add(Dropout(0.5))\n","model.add(Dense(60, activation=\"relu\"))\n","#model.add(Dropout(0.5))\n","model.add(Dense(30, activation=\"relu\"))\n","model.add(Dense(10, activation=\"softmax\"))\n","\n","# Comprobemos la estructura de la red\n","model.summary()\n","\n","# Compilamos y entrenamos el modelo SGD. Sacamos el accuracy.\n","print(\"[INFO]: Entrenando red neuronal...\")\n","model.compile(loss=\"categorical_crossentropy\", optimizer=SGD(0.005), metrics=[\"accuracy\"])\n","H = model.fit(mnist.train.images, mnist.train.labels, validation_data=(mnist.validation.images, mnist.validation.labels), epochs=50, batch_size=128)\n","\n","# Evaluando el modelo de predicción con las imágenes de test\n","print(\"[INFO]: Evaluando red neuronal...\")\n","predictions = model.predict(mnist.test.images, batch_size=128)\n","print(classification_report(mnist.test.labels.argmax(axis=1), predictions.argmax(axis=1)))\n","\n","# Muestro gráfica de accuracy y losses\n","plt.style.use(\"ggplot\")\n","plt.figure()\n","plt.plot(np.arange(0, 50), H.history[\"loss\"], label=\"train_loss\")\n","plt.plot(np.arange(0, 50), H.history[\"val_loss\"], label=\"val_loss\")\n","plt.plot(np.arange(0, 50), H.history[\"acc\"], label=\"train_acc\")\n","plt.plot(np.arange(0, 50), H.history[\"val_acc\"], label=\"val_acc\")\n","plt.title(\"Training Loss and Accuracy\")\n","plt.xlabel(\"Epoch #\")\n","plt.ylabel(\"Loss/Accuracy\")\n","plt.legend()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-YKdKe1emB_2","colab_type":"text"},"source":["\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"UFWzTPW2mpdk","colab_type":"text"},"source":["**EJERCICIO 2.** A continuación vamos a trabajar con un dataset un poco más complejo, **[CIFAR10](https://www.cs.toronto.edu/~kriz/cifar.html)**. Dicho conjunto de datos se compone de **60000 imágenes RGB** de dimensiones **32x32** pertenecientes a **10 clases distintas** (6000 imágenes por clase). CIFAR10 se separa en dos subconjuntos de datos: **50000** imágenes para **entrenamiento** y las **10000** restantes se emplean como set de **test**. \n"]},{"cell_type":"code","metadata":{"id":"NHo6Y2ovkZw7","colab_type":"code","colab":{}},"source":["# Importando el set de datos CIFAR10\n","from keras.datasets import cifar10\n","from sklearn.preprocessing import LabelBinarizer\n","print(\"[INFO] loading CIFAR-10 data...\")\n","((trainX, trainY), (testX, testY)) = cifar10.load_data()\n","# Transformamos los valores de intensidad al rango 0-1\n","trainX = trainX.astype(\"float\") / 255.0\n","testX = testX.astype(\"float\") / 255.0\n","# Etiquetas del dataset\n","labelNames = [\"Avión\", \"Automóvil\", \"Pájaro\", \"Gato\", \"Ciervo\", \"Perro\", \"Rana\", \"Caballo\", \"Barco\", \"Camión\"]\n","# Por si es necesario convertir a one-hot encoding\n","#lb = LabelBinarizer()\n","#trainY = lb.fit_transform(trainY)\n","#testY = lb.transform(testY)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BlvePjz963Nf","colab_type":"text"},"source":["Ahora que tenemos en memoria el set de datos CIFAR10, lo primero que debemos hacer es **mostrar unas cuantas imágenes** para visualizar la **variabilidad** existente:"]},{"cell_type":"code","metadata":{"id":"-Dbpt29E70XU","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","fig = plt.figure(figsize=(14,10))\n","for n in range(1, 29):\n","    fig.add_subplot(4, 7, n)\n","    img = trainX[n]\n","    plt.imshow(img)\n","    plt.title(labelNames[trainY[n][0]])\n","    plt.axis('off')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yeDJKmIdWTP7","colab_type":"text"},"source":["1. Entrena una red perceptron multicapa con dos capas ocultas (la primera de ellas de **1024** neuronas y la segunda de **512**). Emplea como función de activación **ReLU** y **SGD** como optimizador con una tasa de aprendizaje **```lr = 0.01```**. Como función de pérdidas utilizaremos ***categorical crossentropy***. Entrenad la red con valores de **```epochs = 50```** y **```batch_size = 32```**.\n","\n","  **Nota.** Prestad atención a como se cargan los datos, en caso de que se carguen  etiquetas en decimal se deberá emplear el método **```sparse_categorical_crossentropy```** o en su caso utilizar el objeto **LabelBinarizer** de la librería **ScikitLearn** para convertir las etiquetas a one hot encoding (i.e. etiquetas binarias) y poder emplear como función objetivo **```categorical_crossentropy```**. Busca en la documentación las diferencias entre ambos métodos y explicalas. Además el tipo de datos de nuestras etiquetas también hay que tenerlo en cuenta cuando hagamos uso del método **```classification_report```** para obtener las métricas de evaluación de nuestro modelo.\n","\n","2. En caso de que la red no alcance una buena precisión prueba a dotarla de más profundidad. Concretamente incluye cinco capas ocultas con **2048, 1024, 512, 128 y 32** neuronas, respectivamente. Comenta los resultados comparando ambas arquitecturas de red. En caso de que se evidencien signos de overfitting realiza una **segunda ejecución de esta arquitectura** incluyendo una capa de **dropout** tras cada *hidden layer*. ¿Que sucede?\n","\n"]},{"cell_type":"code","metadata":{"id":"5C88mYy1rSiR","colab_type":"code","colab":{}},"source":["# Imports necesarios\n","import numpy as np\n","from sklearn.metrics import classification_report\n","from keras.models import Sequential\n","from keras.layers.core import Dense\n","from keras.optimizers import SGD\n","import matplotlib.pyplot as plt\n","\n","# Pasamos los datos a vector con la función reshape\n","# ???\n","# ???\n","\n","# Arquitectura de red\n","# Definimos el modo API Sequential\n","# ???\n","# Primera capa oculta\n","# ???\n","# Segunda capa oculta\n","# ???\n","# Tercera capa oculta\n","# ???\n","# Cuarta capa oculta\n","# ???\n","# Quinta capa oculta\n","# ???\n","# Capa de salida\n","# ???\n","\n","# Compilamos el modelo sacando el accuracy y entrenamos\n","print(\"[INFO]: Entrenando red neuronal...\")\n","# Compilamos el modelo\n","# ???\n","\n","# Entrenamos el perceptrón multicapa\n","# ???\n","\n","# Evaluamos con las muestras de test\n","print(\"[INFO]: Evaluando modelo...\")\n","# Efectuamos predicciones\n","# ???\n","# Obtenemos el report (requiere etiquetas y predicciones categóricas)\n","# ???\n","\n","# Mostramos gráfica de accuracy y losses\n","plt.style.use(\"ggplot\")\n","plt.figure()\n","plt.plot(np.arange(0, 50), H.history[\"loss\"], label=\"train_loss\")\n","plt.plot(np.arange(0, 50), H.history[\"val_loss\"], label=\"val_loss\")\n","plt.plot(np.arange(0, 50), H.history[\"acc\"], label=\"train_acc\")\n","plt.plot(np.arange(0, 50), H.history[\"val_acc\"], label=\"val_acc\")\n","plt.title(\"Training Loss and Accuracy\")\n","plt.xlabel(\"Epoch #\")\n","plt.ylabel(\"Loss/Accuracy\")\n","plt.legend()\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xl0r189VMeEt","colab_type":"text"},"source":["\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"aKSPU6hhr9_l","colab_type":"text"},"source":["Tal y como hemos visto en la sesión teórica, en la mayoría de problemas de clasificación de imagen, no es suficiente con crear un modelo de predicción basado en un perceptrón multicapa. Para problemas de cierta dificultad, este tipo de arquitectura no ofrece una solución precisa. Por este motivo se propusieron las **redes neuronales convolucionales**. Dichas arquitecturas de red **extraen la información relevante automáticamente** de la imagen por medio de la operación convolución de manera local (en la práctica dicha operación es la correlación cruzada). "]},{"cell_type":"markdown","metadata":{"id":"TxAaE5dycfnQ","colab_type":"text"},"source":["**EJERCICIO 3.** En el siguiente ejercicio vamos a desarrollar **nuestra primera red neuronal convolucional** y entrenarla sobre el **conjunto de datos CIFAR10**. Para ello, vamos a definir en el método ```shallow_CNN(width, heigh, depth, classes)```una arquitectura de red formada por **un único bloque convolucional** compuesto por una capa convolucional (**Conv2D** en Keras) de **32 filtros 3x3** empleando **```padding=\"same\"```** y  la función de activación **ReLu**. Posteriormente, **estiraremos el volumen** resultante y lo llevaremos a una **capa de salida** compuesta por **10 neuronas**. Como se ha detallado en la sesión teórica, Keras tiene dos métodos distintos para implementar la arquitectura de red: el secuencial y el funcional. Implementa esta primera red convolucional utilizando el **método secuencial**. De nuevo emplea **SGD** como optimizador con una tasa de aprendizaje **```lr = 0.01```**. Como función de pérdidas utilizaremos ***categorical crossentropy*** (para etiquetas binarias o decimales según el caso). Entrenad la red con valores de **```epochs = 50```** y **```batch_size = 32```**. ¿Se produce una mejora sustancial con respecto a la arquitectura perceptrón multicapa? ¿Que crees que necesita nuestra CNN? \n","\n","**Nota.** Emplead el padding necesario para que las dimensiones del mapa de activación tras la capa convolucional se mantengan intactas."]},{"cell_type":"code","metadata":{"id":"TVTXeNSYc51v","colab_type":"code","colab":{}},"source":["# import the necessary packages\n","import numpy as np\n","from sklearn.metrics import classification_report\n","from keras.models import Sequential\n","from keras.layers.core import Dense\n","from keras.optimizers import SGD\n","import matplotlib.pyplot as plt\n","from keras.layers.convolutional import Conv2D\n","from keras.layers.core import Activation\n","from keras.layers.core import Flatten\n","from keras import backend as K\n","\n","def shallow_CNN(width, height, depth, classes):\n","  # Definimos el modo API Sequential y las dimensiones de la entrada (suponemos TF->\"channels last\")\n","  # ???\n","  # ???\n","  # Definir la arquitectura\n","  # Capa convolucional\n","  # ???\n","  # Clasificación\n","  # Estiramos el volumen de activación a un vector\n","  # ???\n","  # Añadimos capa de salida\n","  # ???\n","  # La función debe devolver el modelo como salida\n","  # ???\n","\n","# Compilar el modelo\n","print(\"[INFO]: Compilando el modelo...\")\n","# Instanciamos el modelo ajustado al dataset CIFAR10\n","# ???\n","# Compilamos el modelo sacando el accuracy\n","# ???\n","\n","# Entrenamiento de la red\n","print(\"[INFO]: Entrenando la red...\")\n","# ???\n","\n","# Evaluación del modelo\n","print(\"[INFO]: Evaluando el modelo...\")\n","# Efectuamos la predicción (empleamos el mismo valor de batch_size que en training)\n","# ???\n","# Sacamos el report para test\n","# ???\n","\n","# Gráficas\n","plt.style.use(\"ggplot\")\n","plt.figure()\n","plt.plot(np.arange(0, 50), H.history[\"loss\"], label=\"train_loss\")\n","plt.plot(np.arange(0, 50), H.history[\"val_loss\"], label=\"val_loss\")\n","plt.plot(np.arange(0, 50), H.history[\"acc\"], label=\"train_acc\")\n","plt.plot(np.arange(0, 50), H.history[\"val_acc\"], label=\"val_acc\")\n","plt.title(\"Training Loss and Accuracy\")\n","plt.xlabel(\"Epoch #\")\n","plt.ylabel(\"Loss/Accuracy\")\n","plt.legend()\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AkyIzni-Nnai","colab_type":"text"},"source":["De los resultados extraidos del apartado anterior se puede observar que para separar los datos de CIFAR10 en las distintas clases que lo componen requerimos de un **mayor número de bloques convolucionales**. Cuando esto sucede es necesario **introducir capas de pooling** entre bloques convolucionales sucesivos con el objetivo de reducir las dimensiones espaciales de un bloque al siguiente a la vez que aumenta el número de mapas de activación.\n","\n","**EJERCICIO 4.** A continuación vamos a construir una **arquitectura** más avanzada **compuesta por dos bloques convolucionales (*base model*) y un bloque destinado a la clasificación (*top model*)** tal y como se muestra en la imagen siguiente:\n","\n","![CNN_CIFAR10](https://drive.google.com/uc?id=1F6upnZDAp6su41bSegUJmRZgwXlsnqmY)\n","\n","\n","Codifica la arquitectura de la figura anterior en una función definida como:\n","\n","   >>>```deep_CNN(width, height, depth, classes, batchNorm)```\n","\n","El parámetro de entrada **```batchNorm```** debe ser una **bandera** a partir de la cual se aplique la técnica de **Batch Normalization** en los lugares indicados en la arquitectura en el caso que ```batchNorm=True```. En caso contrario no se aplicará dicha técnica. En este ejercicio **SE DEBE** emplear la **API funcional de Keras** para crear la arquitectura. Cabe destacar que en esta ocasión al tratarse de una red con mayor profundidad vamos a aplicar la técnica de **learning rate decay** y **nesterov acceleration** con valores **```decay=lr/epochs```** y **```momentum=0.9```**, respectivamente.  \n","\n","- Ejecutad el entrenamiento con valores de **```epochs = 50```** y **```batch_size = 64```**. ¿Que se pueden decir ahora sobre los resultados de clasificación?¿Existe alguna diferencia entre la ejecución con ```batchNorm=True``` y ```batchNorm=False```?  \n","\n","**Nota 1.** Emplear el padding necesario para que las dimensiones del mapa de activación tras cualquier capa convolucional se mantengan intactas.\n","\n","**Nota 2.** La fase de **entrenamiento** en este ejercicio ya empieza a consumir un **tiempo considerable** de la sesión. Es por ello, que con tal de evitar que tengaís que volver a realizar el entrenamiento en caso de cierre insesperado del navegador o cualquier otro error **GUARDAD el modelo** una vez entrenado en un directorio de vuestro Google Drive (i.e. **/My Drive/Curso_CFP_DL/P4/Models**). Para montar Google Drive en vuestro código en Colab leed las trasparencias de la sesión teórica. Para almacenar el modelo entrenado emplead la fúncion de Keras **```mymodel.save(path)```** (no sin antes leer la documentación de la misma)\n"]},{"cell_type":"code","metadata":{"id":"PbOZdXV5y9BS","colab_type":"code","colab":{}},"source":["# import the necessary packages\n","import numpy as np\n","from keras import backend as K\n","from keras.layers.convolutional import Conv2D\n","from keras.layers import Input\n","from keras.models import Model\n","from keras.layers.core import Activation, Flatten, Dense, Dropout\n","from keras.layers.normalization import BatchNormalization\n","from keras.layers.convolutional import MaxPooling2D\n","from keras.models import Sequential\n","from keras.optimizers import SGD\n","from sklearn.metrics import classification_report\n","import matplotlib.pyplot as plt\n","from google.colab import drive\n","\n","def deep_CNN(width, height, depth, classes, batchNorm):\n","  \n","  # Definimos entradas en modo \"channels last\"\n","  # ???\n","    \n","  # Definimos la arquitectura\n","  # Primer set de capas CONV => RELU => CONV => RELU => POOL\n","  # ???\n","  if batchNorm: \n","    # ???\n","  # ???\n","  if batchNorm:\n","    # ???\n","  # ???\n","  # ???\n","  \n","  # Segundo set de capas CONV => RELU => CONV => RELU => POOL\n","  # ???\n","  if batchNorm:\n","    # ???\n","  # ???\n","  if batchNorm:\n","    # ???\n","  # ???\n","  # ???\n","  \n","  # Primer (y único) set de capas FC => RELU\n","  # ???\n","  # ???\n","  if batchNorm:\n","    # ???\n","  # ???\n","  # Clasificador softmax\n","  # ???\n","  \n","  # Unimos las entradas y el modelo mediante la función Model con parámetros inputs y ouputs (Consultar la documentación)\n","  # ???\n","  \n","  # La función debe devolver el modelo como salida           \n","  # ???\n","\n","# Compilar el modelo\n","print(\"[INFO]: Compilando el modelo...\")\n","# Instanciamos el modelo ajustado al dataset CIFAR10\n","# ???\n","# Compilamos el modelo sacando como mérica el accuracy\n","# ???\n","\n","# Entrenamiento de la red\n","print(\"[INFO]: Entrenando la red...\")\n","# ???\n","\n","# Almaceno el modelo en Drive\n","# Montamos la unidad de Drive\n","# ???\n","# Almacenamos el modelo empleando la función mdoel.save de Keras\n","# ???\n","\n","# Evaluación del modelo\n","print(\"[INFO]: Evaluando el modelo...\")\n","# Efectuamos la predicción (empleamos el mismo valor de batch_size que en training)\n","# ???\n","# Sacamos el report para test\n","# ???\n","\n","# Gráficas\n","plt.style.use(\"ggplot\")\n","plt.figure()\n","plt.plot(np.arange(0, 50), H.history[\"loss\"], label=\"train_loss\")\n","plt.plot(np.arange(0, 50), H.history[\"val_loss\"], label=\"val_loss\")\n","plt.plot(np.arange(0, 50), H.history[\"acc\"], label=\"train_acc\")\n","plt.plot(np.arange(0, 50), H.history[\"val_acc\"], label=\"val_acc\")\n","plt.title(\"Training Loss and Accuracy\")\n","plt.xlabel(\"Epoch #\")\n","plt.ylabel(\"Loss/Accuracy\")\n","plt.legend()\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ml_mODUHkx7y","colab_type":"text"},"source":["**EJERCICIO 5.** Por útlimo, vamos a **desarrollar un método** que a partir de un modelo de predicción ya entrenado y **una imagen de test**, muestre la misma por pantalla incluyendo **la clase a la que pertenece** y el **nivel de confianza** que ofrece el modelo en dicha predicción en el título de la figura. Para ello, comprobad si existe la variable que contenía el modelo anterior (```if 'model' not in locals():```) y en caso negativo cargad el modelo anteriormente almacenado en Drive empleando el comando de Keras **load_model(path)**. La cabecera de la función será la siguiente:\n","\n",">>>>>> ```def predict_image(image, model, gt_str):```\n","\n","Cabe destacar que el tercer parámetro de entrada **```gt_str```** es una **cadena de texto** que valdrá CIFAR10 en caso que estemos prediciendo imágenes de dicho set de datos (por defecto) y el String con el *ground-truth* en caso de que estemos prediciendo imágenes externas (siguiente ejercicio).\n","**Ejecutad** dicho método entre **10-15 veces** variando la imagen a testear de las del **conjunto de test de CIFAR10**. ¿Que puedes decir sobre el éxito en la predicción del modelo generado? "]},{"cell_type":"code","metadata":{"id":"ungocmHJkv7n","colab_type":"code","colab":{}},"source":["import cv2\n","import matplotlib.pyplot as plt\n","import imutils\n","import numpy as np\n","from google.colab import drive\n","from keras.models import load_model\n","\n","def predict_image(image, model, gt_str=\"CIFAR10\"):\n","  # Creamos una copia en la variable output sobre la que mostraremos el resultado (comando image.copy())\n","  # ???\n","  # Expandimos las dimensiones de la variable image de (32, 32, 3) a (1, 32, 32, 3) con np.expand_dims\n","  # ???\n","\n","  # Clasificación de la imagen empleando el modelo\n","  print(\"[INFO]: Clasificando imagen...\")\n","  # Realizamos la predicción y la almacenamos en la variable proba\n","  # ???\n","  print(proba)\n","  # Nos quedamos con la clase que presente una probabilidad mayor y buscamos la etiqueta en el vector labelNames\n","  # ???\n","  # ???\n","  # ???\n","  # En caso que en la variable gt_str no me pasen el string \"CIFAR10\" es que me estan pasando el string con la etiqueta\n","  # Si ese es el caso almaceno el gt de ese String (esto nos valdrá para predecir imágenes que no sean del dataset CIFAR10)\n","  if gt_str != \"CIFAR10\":\n","    # ???\n","\n","  # Mostrando imagen e información\n","  label = \"Predicción: {} - Confianza: {:.2f}% - Ground Truth: {}\".format(label, proba[0][idx] * 100, gt)\n","  plt.imshow(output)\n","  plt.title(label)\n","  plt.show()\n","\n","# Escogemos una imagen de test al azar tal y como se hizo al principio de la práctica anterior\n","# para mostrar numeros de MNIST aleatoriamente (consultala si es necesario)\n","# ???\n","# ???\n","if 'model' not in locals():\n","  # Montamos la unidad de Drive\n","  # ???\n","  # Cargamos el modelo empleando la función load_model\n","  # ???\n","# Predecimos la imagen (llamando a predict_image) pasando como parámetros la imagen, el modelo y la cadena de texto correspondiente\n","# ???"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"e14yj3ykVA-e","colab_type":"text"},"source":["A continuación, cread un directorio en vuestro Google Drive (i.e. **/My Drive/Curso_CFP_DL/P4/Imagenes**) y almacenad diferentes imágenes obtenidas bien de Internet o de vuestras colecciones de imágenes personales (unas 10 imágenes). Empleando OPENCV leed una imagen del directorio y efectuar la predicción empleando el método anterior. Ahora el ground truth no lo teneís directamente disponible por lo que deberéis modificar la función para pasarle un String que contenga la etiqueta solución.\n","\n","Predecid las 10 imágenes almacenadas en vuestro Google Drive, ¿Que puedes decir sobre el **éxito en la predicción del modelo** generado sobre **imágenes NO pertenecientes** al dataset **CIFAR10**?¿A que cree que puede ser debido este fenómeno?¿Que soluciones deberiamos adoptar para mejorar la precisión en la clasificación?"]},{"cell_type":"code","metadata":{"id":"O1nP9VOK9wst","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","\n","# Montamos la unidad de Drive\n","# ???\n","\n","# Selecciono imagen y la leo con OPENCV\n","img_path = # ??? # Path de Drive donde tengo la imagen (incluido el nombre de la misma) #(X)\n","img_test = cv2.imread(img_path, cv2.IMREAD_COLOR) # Leo imagen con OPENCV\n","img_test = cv2.cvtColor(img_test,cv2.COLOR_BGR2RGB) # Por defecto la carga en BGR, la convierto a RGB\n","\n","# Muestro información de la imagen y hago la predicción sacando resultados\n","print(img_test.shape)\n","plt.imshow(img_test)\n","plt.title('my picture')\n","plt.show()\n","\n","# Pre-procesamos tal y como hicimos para la fase de entrenamiento con las muestras de CIFAR10 (normalizándola de 0.0 a 1.0)\n","# ???\n","# Re-escalamos la imagen al tamaño con el que fue entrenada la red (comando cv2.resize)\n","# ???\n","# Predecimos la imagen pasando como parámetros a la función predict_image: la imagen, el modelo y string con el GT\n","# ???"],"execution_count":0,"outputs":[]}]}